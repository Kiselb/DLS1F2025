{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkpqdCk8f4d4"
      },
      "source": [
        "# **Итоговый проект Deep Learning (семестр 1, осень 2025)**\n",
        "\n",
        "**Студент**: Михаил Киселёв\n",
        "\n",
        "**Stepik ID**: 1027756045"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm4u8wLto_WY"
      },
      "source": [
        "# Обзор литературы по Face Recognition: от классики до современных нейросетевых методов (2025)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofeEi-NCpXzm"
      },
      "source": [
        "## 1.1. Краткие выжимки из основополагающих статей\n",
        "### 1.1.1 Eigenfaces (Turk & Pentland, 1991)\n",
        "**Суть**: Первый успешный подход к распознаванию лиц с использованием метода главных компонент (PCA). Лицо представляется как линейная комбинация \"собственных лиц\" (eigenfaces) — основных компонент, извлеченных из набора обучающих изображений.\n",
        "\n",
        "**Ключевая идея**: Проекция изображения лица в низкоразмерное пространство, где расстояние между проекциями (обычно евклидово) определяет сходство.\n",
        "\n",
        "**Ограничения**: Чрезвычайно чувствителен к освещению, позе, выражению лица и требует строгого выравнивания.\n",
        "\n",
        "### 1.1.2 Fisherfaces (Belhumeur et al., 1997)\n",
        "**Суть**: Улучшение метода Eigenfaces с применением **линейного дискриминантного анализа (LDA)**, который максимизирует отношение межклассовой дисперсии к внутриклассовой.\n",
        "\n",
        "**Ключевая идея**: В отличие от PCA, которая максимизирует общую дисперсию, LDA ищет такое подпространство, которое **лучше разделяет разные классы (лица)**, уменьшая влияние вариаций внутри одного класса (освещение, выражение).\n",
        "\n",
        "**Результат**: Более высокая точность по сравнению с Eigenfaces в условиях изменяющегося освещения.\n",
        "\n",
        "### 1.1.3 DeepFace (Taigman et al., 2014) — Начало эры глубокого обучения\n",
        "**Суть**: Первая работа, показавшая, что глубокие сверточные нейросети (CNN) могут достигать точности, близкой к человеческой, на стандартном наборе данных **Labeled Faces in the Wild (LFW) (~97.35%)**.\n",
        "\n",
        "**Ключевая инновация**: Использование сложного 3D-выравнивания лица (\"frontalization\") перед подачей в сеть, что значительно снижает вариативность позы.\n",
        "\n",
        "**Значение**: Доказала практическую применимость глубокого обучения для FR и задала новый стандарт производительности.\n",
        "\n",
        "### 1.1.4 FaceNet (Schroff et al., 2015) — Парадигма эмбеддингов\n",
        "**Суть**: Предложена тройственная функция потерь (Triplet Loss) и архитектура для прямого обучения компактного евклидова векторного представления лица (128-D эмбеддинг).\n",
        "\n",
        "**Ключевая идея**: Сеть обучается так, чтобы расстояние между эмбеддингами одного человека (anchor и positive) было меньше, чем расстояние между эмбеддингами разных людей (anchor и negative) на заданную величину (margin).\n",
        "\n",
        "**Значение**: Установила новую парадигму **\"одна сеть — один эмбеддинг\"**, которая стала основой для большинства современных промышленных систем. Достигла 99.63% на LFW."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaGy7ImlqzsJ"
      },
      "source": [
        "## 1.2. Основные современные алгоритмы и методы FR с использованием нейросетей (на 2025 год)\n",
        "Современный пайплайн FR состоит из стандартных этапов:\n",
        "\n",
        "- Детекция лица (например, RetinaFace, MTCNN, YOLO-based).\n",
        "\n",
        "- Выравнивание и нормализация (ключевые точки, аффинные преобразования).\n",
        "\n",
        "- Извлечение признаков (Feature Extraction) с помощью CNN.\n",
        "\n",
        "- Сравнение эмбеддингов (метрика косинусного или евклидова расстояния).\n",
        "\n",
        "### 1.2.1 Архитектуры сетей (Backbones)\n",
        "Используются современные CNN и Vision Transformers, претренированные на огромных наборах данных (MS-Celeb-1M, WebFace, VGGFace2):\n",
        "\n",
        "- **ResNet и его вариации (ResNet-50, ResNet-100, SE-ResNet)**: Стандартный выбор благодаря остаточным связям, решающим проблему затухания градиента.\n",
        "\n",
        "- **EfficientNet**: Обеспечивает лучшее соотношение точности и вычислительной эффективности за счет масштабирования глубины, ширины и разрешения.\n",
        "\n",
        "- **Vision Transformers (ViT, Swin Transformer)**: Набирают популярность, показывая SOTA-результаты на некоторых бенчмарках за счет глобального внимания к патчам изображения. Требуют больше данных для обучения.\n",
        "\n",
        "### 1.2.2 Ключевые функции потерь (Loss Functions)\n",
        "Эволюция loss-функций — основной драйвер прогресса в FR. Их цель — сделать **эмбеддинги одного класса максимально компактными, а разных классов — максимально разделенными в пространстве признаков**.\n",
        "\n",
        "#### 1.1.2.1. Кросс-энтропийная потеря (Softmax Loss / CE Loss)\n",
        "\n",
        "**Описание**: Классическая функция для классификации. Сеть обучается предсказывать конкретный класс (человека) из фиксированного набора.\n",
        "\n",
        "**Проблема**: Напрямую не оптимизирует компактность внутри класса и разделимость между классами. Эмбеддинги одного человека могут быть разбросаны, если они правильно классифицированы.\n",
        "\n",
        "#### 1.1.2.2. Loss-функции с добавлением маржи (Margin-based Losses)\n",
        "Для решения проблемы Softmax Loss были предложены функции, которые добавляют угловую или косинусную маржу (margin) в пространстве признаков, создавая более жесткую границу решения.\n",
        "\n",
        "- **ArcFace** (Additive Angular Margin Loss, 2019) — Наиболее популярная и эффективная.\n",
        "\n",
        "  - **Формула**: $\n",
        "\\mathcal{L} = -\\frac{1}{M}\\sum_{i=1}^{M} \\log\\frac{e^{s*\\cos(\\theta_{y_i} + m)}}\n",
        "{e^{s*\\cos(\\theta_{y_i} + m)} + \\sum_{j \\neq y_i} e^{s*\\cos\\theta_j}}\n",
        "$\n",
        "\n",
        "  - **Идея**: Добавляет аддитивную угловую маржу m (например, 0.5 радиан) непосредственно к углу θ между вектором весов класса W_yi и признаком x_i. Это сужает угловой сектор, отведенный для каждого класса.\n",
        "\n",
        "  - **Преимущества**:\n",
        "\n",
        "    - Четкая геометрическая интерпретация в угловом пространстве.\n",
        "\n",
        "    - Обеспечивает максимально возможную разделимость между классами.\n",
        "\n",
        "    - Превосходит другие методы на большинстве бенчмарков.\n",
        "\n",
        "- **Другие важные функции с маржой**:\n",
        "\n",
        "  - **CosFace (Large Margin Cosine Loss, 2018)**: Добавляет маржу к косинусу угла: $cos(θ) - m$.\n",
        "\n",
        "  - **SphereFace (Angular Softmax, 2017)**: Пионерская работа, вводящая мультипликативную угловую маржу $(m*cos(θ))$.\n",
        "\n",
        "### 1.2.3 Методы для работы с ранее не встречающимися классами (Open-Set Recognition)\n",
        "Основная задача — сравнивать эмбеддинги лиц, которых не было в обучающей выборке.\n",
        "\n",
        "- **Метрическое обучение (Metric Learning)**: Использование функций потерь (Triplet Loss, ArcFace), которые напрямую обучают \"хорошему\" пространству для сравнения.\n",
        "\n",
        "- **Нормализация**: Все современные методы используют L2-нормализацию как эмбеддингов, так и весов последнего слоя. Это проецирует точки на гиперсферу, где сравнение косинусного подобия $(cos(θ) = (x·W) / (||x||*||W||))$ становится эквивалентным скалярному произведению нормализованных векторов.\n",
        "\n",
        "- **Пороговая классификация**: Решение \"свой/чужой\" принимается путем сравнения косинусного сходства двух эмбеддингов с заранее выбранным порогом (например, 0.3-0.5)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjdcz4rCvgTl"
      },
      "source": [
        "## 1.3. Ссылки на ключевые статьи по нейросетевым алгоритмам FR\n",
        "**ArcFace**: Deng, J., Guo, J., Xue, N., & Zafeiriou, S. (2019). ArcFace: Additive Angular Margin Loss for Deep Face Recognition. CVPR. https://arxiv.org/abs/1801.07698\n",
        "\n",
        "**CosFace**: Wang, H., et al. (2018). CosFace: Large Margin Cosine Loss for Deep Face Recognition. CVPR. https://arxiv.org/abs/1801.09414\n",
        "\n",
        "**SphereFace**: Liu, W., et al. (2017). SphereFace: Deep Hypersphere Embedding for Face Recognition. CVPR. https://arxiv.org/abs/1704.08063\n",
        "\n",
        "**FaceNet**: Schroff, F., Kalenichenko, D., & Philbin, J. (2015). FaceNet: A Unified Embedding for Face Recognition and Clustering. CVPR. https://arxiv.org/abs/1503.03832\n",
        "\n",
        "**VGGFace2**: Cao, Q., Shen, L., Xie, W., Parkhi, O. M., & Zisserman, A. (2018). VGGFace2: A dataset for recognising faces across pose and age. FG. https://arxiv.org/abs/1710.08092\n",
        "\n",
        "**Более современные обзоры**: Deng, J., & Guo, J. (2020). A Survey of Face Recognition. https://arxiv.org/abs/2004.11823"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF9PsYC6v69M"
      },
      "source": [
        "## 1.4. FaceNet: Глубокое понимание\n",
        "### 1.4.1. Концептуальный прорыв\n",
        "До FaceNet большинство нейросетевых подходов (вроде DeepFace) использовали архитектуру, где последний слой был классификатором на N человек (где N — размер обучающей выборки). Сеть отвечала на вопрос: **\"Кто это из известных мне людей?\"**. Для сравнения двух лиц нужно было либо извлекать признаки из промежуточных слоев (что было неоптимально), либо запускать два лица через сеть и как-то сравнивать их активации.\n",
        "\n",
        "**FaceNet предложил радикально иную идею**: обучить сеть не классификации, а прямому преобразованию лица в компактное, метрическое пространство.\n",
        "\n",
        "### 1.4.2. Ключевые компоненты FaceNet\n",
        "#### 1.4.2.1. Тройственная функция потерь (Triplet Loss).\n",
        "Это сердце метода. Цель — научиться таким эмбеддингам, где:\n",
        "\n",
        "- **Эмбеддинги одного человека** находятся близко друг к другу\n",
        "\n",
        "- **Эмбеддинги разных людей** находятся далеко друг от друга\n",
        "\n",
        "**Математическая формулировка**:\n",
        "Для тройки изображений:\n",
        "\n",
        "- **Anchor (A)** — базовое изображение человека\n",
        "\n",
        "- **Positive (P)** — другое изображение того же человека\n",
        "\n",
        "- **Negative (N)** — изображение другого человека\n",
        "\n",
        "Сеть обучается минимизировать **Triplet Loss**:\n",
        "\n",
        "$L = max( ||f(A) - f(P)||² - ||f(A) - f(N)||² + α, 0 )$\n",
        "\n",
        "где:\n",
        "\n",
        "$f(x)$ — эмбеддинг, полученный из сети (L2-нормализованный)\n",
        "\n",
        "$||·||$ — евклидово расстояние\n",
        "\n",
        "$α$ — **margin** (зазор), гиперпараметр, определяющий, насколько расстояние до negative должно быть больше, чем до positive\n",
        "\n",
        "**Геометрическая интерпретация**: Loss стремится к нулю, когда расстояние между A и P на α меньше, чем расстояние между A и N. То есть positive должен находиться внутри сферы радиуса d(A,P), а negative — за пределами сферы радиуса d(A,P) + α.\n",
        "\n",
        "#### 1.4.2.2. Выбор \"тяжелых\" троек (Triplet Mining)\n",
        "Просто случайный выбор троек неэффективен — большинство из них будут тривиальными (negative и так далеко). **Ключевая инновация FaceNet — стратегия выбора троек**:\n",
        "\n",
        "- **Semi-hard negative mining**: Выбираются такие тройки, где Negative находится дальше Positive от Anchor, но разница меньше margin α:\n",
        "d(A, P) < d(A, N) < d(A, P) + α\n",
        "\n",
        "- **Hard negative mining**: Еще более жесткий отбор, где Negative ближе к Anchor, чем Positive: d(A, N) < d(A, P)\n",
        "\n",
        "Это обеспечивает **информативные примеры**, которые действительно \"заставляют\" сеть учиться разделять похожие, но разные лица.\n",
        "\n",
        "### 1.4.3. Архитектура сети\n",
        "FaceNet использовала **GoogleNet (Inception v1)** в качестве backbone-сети, но концепция была архитектурно-независимой. Главное — последние слои:\n",
        "\n",
        "- Обычные сверточные слои для извлечения признаков\n",
        "\n",
        "- Слой глобального среднего пулинга (Global Average Pooling) вместо полносвязных слоев\n",
        "\n",
        "- L2-нормализация выхода, чтобы все эмбеддинги лежали на гиперсфере единичного радиуса\n",
        "\n",
        "- Выход — 128-мерный вещественный вектор (эмбеддинг)\n",
        "\n",
        "**Почему именно 128 измерений?**\n",
        "Это эмпирический выбор авторов, представляющий баланс между:\n",
        "\n",
        "- Достаточной емкостью для кодирования информации о лице\n",
        "\n",
        "- Компактностью для быстрого сравнения и хранения\n",
        "\n",
        "- Устойчивостью к переобучению\n",
        "\n",
        "### 1.4.4. Парадигма \"Одна сеть — один эмбеддинг\"\n",
        "**Раньше (DeepFace-подход)**:\n",
        "\n",
        "[Изображение лица] → [Сеть-классификатор] → [Вероятности по N классам]\n",
        "\n",
        "Для сравнения двух лиц нужно сравнивать векторы вероятностей или признаки из промежуточных слоев.\n",
        "\n",
        "**Теперь (FaceNet-подход)**:\n",
        "\n",
        "[Изображение лица A] → [Сеть-эмбеддинг] → [Вектор $f(A) ∈ R^{128}$]\n",
        "\n",
        "[Изображение лица B] → [Та же самая сеть] → [Вектор $f(B) ∈ R^{128}$]\n",
        "\n",
        "Сравнение: $distance = ||f(A) - f(B)||$\n",
        "\n",
        "**Преимущества парадигмы**\n",
        "1. **Масштабируемость**\n",
        "- **Добавление нового человека** не требует переобучения всей сети\n",
        "\n",
        "- Для хранения информации о новом лице нужно лишь сохранить **128 чисел (эмбеддинг)**\n",
        "\n",
        "- Поиск среди миллиардов лиц сводится к задаче поиска ближайших соседей (k-NN) в 128-мерном пространстве\n",
        "\n",
        "2. **Естественность для Open-Set Recognition**\n",
        "- **Классификационный подход**: Работает только с известными классами. Что делать с новым человеком?\n",
        "\n",
        "- **Эмбеддинговый подход**: Все лица (известные и неизвестные) проецируются в одно и то же пространство. Новый человек просто получает свои координаты в этом пространстве. Решение \"свой/чужой\" принимается по порогу расстояния.\n",
        "\n",
        "3. **Универсальность применения**\n",
        "Один и тот же эмбеддинг можно использовать для разных задач:\n",
        "\n",
        "- Верификация (1:1): \"Это тот же самый человек?\" → сравнить 2 эмбеддинга\n",
        "\n",
        "- Идентификация (1:N): \"Кто этот человек?\" → поиск ближайшего эмбеддинга в базе\n",
        "\n",
        "- Кластеризация: Группировка лиц по сходству без учителя\n",
        "\n",
        "- Поиск дубликатов в фотоархивах\n",
        "\n",
        "4. **Интерпретируемость пространства**\n",
        "Эмбеддинговое пространство FaceNet обладает интересными свойствами:\n",
        "\n",
        "- Линейные операции: f(король) - f(мужчина) + f(женщина) ≈ f(королева) (аналогия word2vec, но для лиц)\n",
        "\n",
        "- Непрерывность: Малые изменения в изображении → малые изменения в эмбеддинге\n",
        "\n",
        "- Семантическая организация: Похожие лица (близнецы, родственники) находятся рядом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enabyWU72Pi8"
      },
      "source": [
        "## 1.5. Эволюция после FaceNet\n",
        "Хотя FaceNet представил парадигму эмбеддингов, у Triplet Loss были недостатки:\n",
        "\n",
        "- Сложность выбора троек — вычислительно дорого\n",
        "\n",
        "- Медленная сходимость — нужно много эпох\n",
        "\n",
        "- Чувствительность к гиперпараметрам (особенно margin α)\n",
        "\n",
        "Поэтому современные методы (ArcFace, CosFace) используют модифицированный Softmax с маржой, который:\n",
        "\n",
        "- Сохраняет преимущества эмбеддингового подхода\n",
        "\n",
        "- Обучается быстрее и стабильнее\n",
        "\n",
        "- Дает еще более качественные эмбеддинги\n",
        "\n",
        "## 1.6. Промышленное применение сегодня\n",
        "Парадигма \"одна сеть — один эмбеддинг\" стала стандартом де-факто:\n",
        "\n",
        "- Apple Face ID: Использует подобный подход (нейросеть + эмбеддинги)\n",
        "\n",
        "- Системы видеонаблюдения: Хранение и поиск по эмбеддингам\n",
        "\n",
        "- Социальные сети: Автотегирование фотографий\n",
        "\n",
        "- Паспортный контроль: Быстрая верификация\n",
        "\n",
        "## 1.7. Критические замечания\n",
        "**Уязвимость к атакам**: Малые адверсарные возмущения могут изменить эмбеддинг. **Адверсарные возмущения** — это специально созданные, малозаметные для человека искажения входных данных (изображений, аудио, текста), которые заставляют нейронную сеть совершать предсказуемые ошибки. **Ключевая особенность**: эти искажения настолько малы, что человеческий глаз их практически не замечает, но для нейросети они кардинально меняют результат работы.\n",
        "\n",
        "**Проблема смещения (bias)**: Качество разное для разных демографических групп\n",
        "\n",
        "**Вычислительная стоимость инференса**: Нужно прогонять каждое лицо через глубокую сеть\n",
        "\n",
        "**Проблема негативных сэмплов**: При огромных базах (миллионы лиц) \"hard negative mining\" становится вычислительно сложным\n",
        "\n",
        "## 1.8. Заключение\n",
        "**FaceNet** совершил переворот, показав, что:\n",
        "\n",
        "- Можно обучать эмбеддинги напрямую, а не как побочный продукт классификации\n",
        "\n",
        "- Евклидово/косинусное расстояние в эмбеддинговом пространстве — естественная и эффективная мера сходства лиц\n",
        "\n",
        "- Парадигма \"одна сеть для всех\" масштабируется до миллиардов лиц\n",
        "\n",
        "Эта парадигма настолько успешна, что пережила саму архитектуру FaceNet: современные SOTA-модели (с ArcFace и другими loss-функциями) все еще следуют тому же принципу — одна сеть преобразует лицо в вектор, а сравнение векторов дает ответ. **Это фундаментальный сдвиг в мышлении: от \"распознавания\" к \"представлению\"**."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
